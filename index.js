/**
 * Bot Discord + OpenAI ‚Äî Exemple public
 * --------------------------------------
 * Objectif : montrer un bot minimal qui r√©pond avec l'API OpenAI,
 * avec un peu de m√©moire locale et de gardes-fous simples.
 *
 * Comment l'utiliser :
 *   1) Node 18+ recommand√©.
 *   2) `npm i discord.js openai dotenv`
 *   3) Copier `.env.example` -> `.env` et remplir :
 *        TOKEN=...          (token de ton application Discord)
 *        OPENAI_KEY=...     (cl√© API OpenAI)
 *        ALLOW_CHANNELS=123456789012345678,987654321098765432  (optionnel)
 *        MODEL=gpt-4o-mini  (ou autre mod√®le compatible)
 *   4) `node bot.js`
 *
 * Notes importantes :
 *   - Ne JAMAIS committer `.env` sur un repo public.
 *   - `ALLOW_CHANNELS` permet de restreindre les salons o√π le bot r√©pond.
 *   - Ce code utilise un fichier JSON local pour "m√©moriser" le dernier √©change.
 *     C'est suffisant pour un exemple. Pour la production, pr√©f√©rer une base durable.
 */

const fs = require('fs');
require('dotenv/config'); // charge automatiquement les variables depuis .env
const { Client, GatewayIntentBits } = require('discord.js');
const { OpenAI } = require('openai');

// =======================
// 1) V√©rification basique des variables d'environnement
// =======================
if (!process.env.OPENAI_KEY || !process.env.TOKEN) {
  console.error("‚ùå Il manque OPENAI_KEY ou TOKEN dans ton .env");
  process.exit(1);
}

// Liste de salons autoris√©s (optionnel). Si vide => le bot r√©pond partout.
const ALLOW_CHANNELS = (process.env.ALLOW_CHANNELS || process.env.CHANNEL_ID || '')
  .split(',')
  .map(s => s.trim())
  .filter(Boolean);

// =======================
// 2) Petites options de configuration (modifiables via .env)
// =======================
const MEMORY_FILE = 'memory.json';                           // stockage local des historiques
const MESSAGE_LIMIT = parseInt(process.env.MESSAGE_LIMIT || '20', 10); // nb max de tours gard√©s
const ANTI_SPAM_MS = parseInt(process.env.ANTI_SPAM_MS || '3000', 10); // cooldown anti-spam (ms)
const MODEL = process.env.MODEL || 'gpt-4o-mini';            // mod√®le OpenAI configurable
const TEMPERATURE = parseFloat(process.env.TEMPERATURE || '0.7'); // cr√©ativit√© des r√©ponses
const MAX_TOKENS = parseInt(process.env.MAX_TOKENS || '500', 10); // taille max de sortie

// =======================
// 3) Initialisation Discord et OpenAI
// =======================
const client = new Client({
  intents: [
    // Intents n√©cessaires pour lire les messages et y r√©pondre
    GatewayIntentBits.Guilds,
    GatewayIntentBits.GuildMembers,
    GatewayIntentBits.GuildMessages,
    GatewayIntentBits.MessageContent
  ],
});

const openai = new OpenAI({ apiKey: process.env.OPENAI_KEY });

// =======================
// 4) M√©moire simple (par utilisateur) dans un fichier JSON
// =======================
// Structure : { [userId]: { history: [{role, content}, ...], lastInteraction: number } }
let userConversations = {};
if (fs.existsSync(MEMORY_FILE)) {
  try {
    userConversations = JSON.parse(fs.readFileSync(MEMORY_FILE, 'utf8'));
  } catch {
    console.warn("‚ö†Ô∏è Impossible de lire la m√©moire, on repart de z√©ro.");
    userConversations = {};
  }
}
let memoryDirty = false;

// Sauvegarde synchrone (suffisant pour un exemple). Pour un vrai projet : asynchrone + atomique.
function saveMemory(force = false) {
  if (!memoryDirty && !force) return;
  try {
    fs.writeFileSync(MEMORY_FILE, JSON.stringify(userConversations, null, 2));
    memoryDirty = false;
  } catch (e) {
    console.error("‚ùå Erreur de sauvegarde m√©moire :", e);
  }
}

// Sauvegarde √† la fermeture (Ctrl+C)
process.on('SIGINT', () => { 
  console.log("\nüõë Arr√™t demand√© ‚Äî sauvegarde de la m√©moire...");
  saveMemory(true); 
  process.exit(0); 
});

// =======================
// 5) Aides : anti-spam & d√©coupe de messages
// =======================
// Discord limite un message √† 2000 caract√®res. On d√©coupe proprement les textes longs.
function splitForDiscord(text) {
  const CHUNK = 1900; // marge de s√©curit√© si on a des blocs de code
  const out = [];
  let buf = '';
  for (const line of String(text).split('\n')) {
    if ((buf + '\n' + line).length > CHUNK) {
      out.push(buf);
      buf = line;
    } else {
      buf = buf ? buf + '\n' + line : line;
    }
  }
  if (buf) out.push(buf);
  return out;
}

// Anti-spam minimal : impose un d√©lai minimum entre deux messages d'un m√™me utilisateur
const lastMessageTime = {};
function isAllowedChannel(channelId) {
  // Si ALLOW_CHANNELS est vide, on autorise tous les salons
  return ALLOW_CHANNELS.length === 0 || ALLOW_CHANNELS.includes(channelId);
}

// =======================
// 6) Ready : simple log pour confirmer la connexion
// =======================
client.on('ready', () => {
  console.log(`‚úÖ Connect√© en tant que ${client.user.tag}`);
});

// =======================
// 7) √âcoute des messages
// =======================
client.on('messageCreate', async (message) => {
  // a) Ignorer les messages des bots (y compris ce bot)
  if (message.author.bot) return;

  // b) Restreindre aux salons autoris√©s (si tu en as list√©)
  if (!isAllowedChannel(message.channelId)) return;

  // c) Anti-spam : si l'utilisateur envoie trop vite, on ignore
  const now = Date.now();
  const last = lastMessageTime[message.author.id] || 0;
  if (now - last < ANTI_SPAM_MS) return;
  lastMessageTime[message.author.id] = now;

  // d) Indiquer √† Discord que le bot "√©crit" (UX sympa)
  await message.channel.sendTyping();

  // e) Initialiser la m√©moire de cet utilisateur si besoin
  const uid = message.author.id;
  if (!userConversations[uid]) {
    userConversations[uid] = {
      // Le message "system" sert √† donner une personnalit√©/mission au mod√®le
      history: [{ role: 'system', content: 'BotGPT est un chatbot amical et serviable.' }],
      lastInteraction: Date.now()
    };
  }

  // f) Ajouter le message utilisateur √† l'historique
  userConversations[uid].history.push({ role: 'user', content: message.content });
  userConversations[uid].lastInteraction = Date.now();

  // g) Limiter la taille de l'historique (√©vite les co√ªts et les prompts trop longs)
  if (userConversations[uid].history.length > MESSAGE_LIMIT) {
    // on garde l'entr√©e "system" en t√™te, et on coupe le surplus
    userConversations[uid].history.splice(1, userConversations[uid].history.length - MESSAGE_LIMIT);
  }
  memoryDirty = true;

  // h) Appeler l'API OpenAI pour g√©n√©rer la r√©ponse
  let botReply = "D√©sol√©, je n'ai pas de r√©ponse pour le moment.";
  try {
    const resp = await openai.chat.completions.create({
      model: MODEL,                               // mod√®le configurable (via .env)
      messages: userConversations[uid].history,   // historique minimal de la conversation
      temperature: TEMPERATURE,                   // plus haut = plus cr√©atif
      max_tokens: MAX_TOKENS                      // limite la longueur de la r√©ponse
    });

    botReply = resp?.choices?.[0]?.message?.content?.trim() || botReply;
  } catch (e) {
    // En cas d'erreur API (cl√© invalide, quota, r√©seau...), on log + message gentil
    console.error("‚ùå OpenAI error:", e?.message || e);
    botReply = "Oups, un souci c√¥t√© IA. R√©essaie un peu plus tard.";
  }

  // i) M√©moriser la r√©ponse de l'assistant
  userConversations[uid].history.push({ role: 'assistant', content: botReply });
  memoryDirty = true;

  // j) Sauvegarder la m√©moire sur disque (simple et suffisant pour un exemple)
  saveMemory();

  // k) R√©pondre en "chunks" si le message d√©passe 2000 caract√®res
  for (const chunk of splitForDiscord(botReply)) {
    await message.reply({
      content: chunk,
      // Astuce UX : ne pas "ping" l'utilisateur quand on r√©pond
      allowedMentions: { repliedUser: false }
    });
  }
});

// =======================
// 8) Connexion du bot √† Discord
// =======================
client.login(process.env.TOKEN);
